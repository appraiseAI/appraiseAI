---
banner:
  title: " AI Governance with APPRAISE"
  content: "The website is currently undergoing construction. If you're keen to learn more about our work, you can explore our research paper on arXiv using the provided link."
  image: false
  button:
    enable: true
    label: "Link to our arXiv paper"
    link: "https://arxiv.org/abs/2309.14876"


# Features
features:
  - title: "Key Insights into AI Governance"
    image: "/images/logo.png"
    content: "Delve into the our paper on AI governance through our research in the Netherlands. Discover how the proposed APPRAISE framework addresses challenges and provides valuable insights for organizations. "
    bulletpoints:
      - "Learnings from GDPR and their impact on AI governance"
      - "Size matters: Analyzing compliance based on organization size"
      - "The role of audit in ensuring AIA compliance"
    button:
      enable: True
      label: "Link to our arXiv paper"
      link: "https://arxiv.org/abs/2309.14876"


  - title: "An Audit Framework for Technical Assessment of Binary Classifiers"
    image: "/images/service-2.png"
    content: "This paper introduces an audit framework for assessing the technical aspects of logistic regression and random forest models used for binary classification, in line with the European Commission's proposed Artificial Intelligence Act (AIA). The framework covers model, discrimination, transparency, and explainability aspects, utilizing 20 key performance indicators (KPIs) paired with a traffic light risk assessment method. By training models on an open-source dataset and evaluating with various explainability methods, the framework aims to aid regulatory bodies in conformity assessments and assist AI-system providers and users in complying with the AIA."
    bulletpoints:
    - "Examine the rise of multilevel models for binary classification"
    - "Highlight the importance of fairness and transparency under the AIA"
    - "Introduce an audit framework for RFMs and MLogRMs"
    button:
      enable: true
      label: "Read More in the arXiv paper"
      link: "https://arxiv.org/abs/2211.09500"

  - title: "A Framework for Auditing Multilevel Models using Explainability Methods"
    image: "/images/service-3.png"
    content: "Multilevel models are commonly used for binary classification within hierarchical structures, demanding transparent and ethical applications. This paper proposes an audit framework for assessing technical aspects of regression MLMs, focusing on model, discrimination, and transparency/explainability. Contributors like inter-MLM group fairness and feature contribution order are identified, with KPIs proposed for their evaluation using a traffic light risk assessment method. Different explainability methods (SHAP and LIME) are employed and compared for transparency assessment. Utilizing an open-source dataset, model performance is evaluated, highlighting challenges in popular explainability methods. The framework aims to aid regulatory conformity assessments and support businesses in aligning with AI regulations."
    bulletpoints:
    - "Introduce an audit framework for technical assessment of regression MLMs"
    - "Identify contributors and propose KPIs for model evaluation"
    - "Utilize traffic light risk assessment method for evaluation"
    button:
      enable: true
      label: "Read More "
      link: "https://books.google.nl/books?hl=en&lr=&id=4AqiEAAAQBAJ&oi=fnd&pg=PA12&dq=bhaumik+dey+auditing+binary+classifiers&ots=Rd9AM7DUZB&sig=KPBF3Z6dkrwjSwBNHJF-tBlb9Jc&redir_esc=y#v=onepage&q=bhaumik%20dey%20auditing%20binary%20classifiers&f=false"
---

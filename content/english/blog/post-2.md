---
title: "Dutch Companies Insufficiently Prepared for the European AI Act"
meta_title: "Dutch Companies Unprepared for EU AI Act"
description: "This article examines the results of a study by the Amsterdam University of Applied Sciences on the readiness of Dutch organizations for the EU AI Act."
date: 2024-04-13T00:02:10+02:00
image: "/images/newsEU.png"
categories: ["Technology", "Regulation"]
author: "Diptish Dey"
tags: ["AI", "EU AI Act", "Compliance"]
draft: false
---
[Original article in Dutch](https://www.emerce.nl/research/onderzoek-nederlandse-bedrijven-onvoldoende-voorbereid-op-de-europese-ai-wet)

With the historic approval of the EU AI Act (AIA) by the European Parliament, we are on the eve of a new era in the regulation of artificial intelligence within the European Union.

In an era where AI systems are deeply integrated into our daily activities, from e-commerce to social media, the AIA marks a crucial step towards the responsible use of AI. But how ready is the Dutch business community for this new legislation?

In this article, we describe the results of an extensive study by the Amsterdam University of Applied Sciences (HvA) that examined the attitudes of Dutch organizations towards the EU AI Act, their challenges, and their approach. The article concludes with concrete recommendations for organizations to be able to comply with this new legislation.

## The EU AI Act
The consequence of the legislation adopted by the European Parliament is that organizations must comply with the requirements of the AIA within a maximum of three years. This period may vary, depending on the type of AI systems used (for example, only six months). Therefore, it is crucial that organizations start preparing to comply with the AIA as soon as possible.

The AIA clearly states which AI applications are prohibited and identifies AI systems that are considered high-risk. These practices and systems must meet strict criteria before they can be brought to market. For example, recommendation systems that profile individuals must be thoroughly analyzed before they can be deployed.

Such systems are now used in many sectors, including e-commerce, social media, and music and video streaming services. AI systems for selecting candidates in recruitment processes are also an example of high-risk systems.

In addition to AI systems specifically designed for predictive purposes, there has recently been a significant growth in the development of general AI models, including OpenAI's Large Language Models. When organizations decide to develop their own AI system based on these models, this can also lead to the classification of the system as high-risk.

## The Research
In anticipation of the expected approval of the AIA by the European Parliament, the HvA conducted research into its compliance by organizations and the main causes of non-compliance. This research specifically focused on organizations using predictive AI technologies. These technologies are known for their potential to radically transform business models and stimulate significant innovation in products and services. This is in contrast to generative AI, which is primarily aimed at increasing efficiency and innovation within existing work processes by automating the creation of content (including text, images, video, audio, and code).

The research was conducted in two phases. During the first phase, structured in-depth interviews were conducted with thirty-four Dutch organizations. The second phase consisted of case studies of two of these organizations. The research aimed to assess compliance with the AIA, identify the main reasons for compliance or lack thereof, and make recommendations for actions organizations can take to comply with the AIA.

Among the organizations interviewed were established market leaders in health insurance, consumer goods, access control, HR services, and online retail. There were also SMEs, ranging in size from fifty to five hundred employees. A third of these organizations systematically outsource the development of their AI systems, often to offshore locations in Asia. The respondents also varied in their level of knowledge of the AIA.

## The Gap Between Expectation and Reality
Many organizations still have a limited understanding of the requirements to fully comply with the AIA. With an average compliance score of only 56 percent, the interviewed companies are significantly far from the one hundred percent compliance required to fully meet the AIA.

This emphasizes that they still have considerable steps to take to achieve total compliance with the AIA. Furthermore, it appears that about sixty percent of the surveyed organizations overestimate the extent to which they comply with this new European legislation. SMEs generally score lower in their compliance with the AIA than larger organizations. The structured in-depth interviews were specifically designed to accurately measure the difference between the actual compliance and the assumed compliance by the organizations.

The research further shows that many organizations are trying to comply with the AIA requirements in creative ways. A common practice is to generate technical documentation at the end of the model development process, rather than doing it continuously. This suggests that while organizations recognize the importance of technical documentation, they place less value on its quality by not regularly updating or improving it.

Furthermore, the measures taken to comply with the AIA often seem limited in scope. Even in cases where organizations verify that their models and data are free from bias, there is often a lack of continuous monitoring of the model. This is crucial to ensure that their AI systems do not evolve over time to unacceptable levels of bias. Especially with recommendation systems, unacceptable bias can quickly arise, as these systems are designed to learn autonomously in real-time.

## Decision-Making and Implementation
The interview questions were not only focused on operational aspects, such as the specific compliance actions that organizations are taking, but also aimed to gain insight into the influence of strategic factors and decision-making on compliance with the AIA. The consequences of strategic choices, such as outsourcing and offshoring activities, on compliance with the AIA are often underestimated.

To illustrate: one of the interviewed organizations has opened an office in Asia to carry out all its model development activities there. Differences in ethical standards and the interpretation of legal frameworks internationally can lead to models developed in Asia not meeting European standards. This problem is exacerbated by the fact that some of these models are highly black-box in nature, making it difficult to explain their functioning afterwards. When making such strategic decisions, organizations are often driven by the pursuit of value creation, cost savings, and leveraging labor potential, which can cause them to underestimate the importance of regulation in their strategic considerations.

Ultimately, it is important that organizations implementing AI systems develop a governance model that facilitates compliance with the AIA. Although it is of crucial importance to integrate AI strategically into the organization, the main challenge for organizations remains how to ensure that their algorithms meet the requirements of the AIA. Depending on the complexity of the algorithm, this can be a major challenge, and sometimes even seem unfeasible based on current knowledge. As recently noted by a Member of the European Parliament involved in the AIA: "We need big brains like Oppenheimer to make its rules work".

About the authors: Dr. Diptish Dey is a researcher and investor in artificial intelligence and data science, and Dr. Jesse Weltevreden is a professor of Digital Commerce. Both are affiliated with the Centre of Expertise Applied AI and the Centre for Market Insights of the Amsterdam University of Applied Sciences.
